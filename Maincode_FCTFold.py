# -*- coding: utf-8 -*-
"""Maincode_PSSP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DNN7KScsBffFiQmas_noS9atUZKAKDZE
"""



# ========================== #
# IMPORT REQUIRED LIBRARIES #
# ========================== #

import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras import layers, models, optimizers, callbacks
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef
import tensorflow as tf


# ========================================== #
# TRANSFORMER ENCODER ON WINDOWED SEQUENCES #
# ========================================== #

def windowed_transformer_encoder(x, window_size=16, num_heads=8, key_dim=64):
    def pad_to_window(x_in, win_size=window_size):
        seq_len = tf.shape(x_in)[1]
        padding = (win_size - (seq_len % win_size)) % win_size
        return tf.pad(x_in, [[0, 0], [0, padding], [0, 0]])

    x = layers.Lambda(pad_to_window)(x)

    def dynamic_reshape(x_in, win_size=window_size):
        batch_size = tf.shape(x_in)[0]
        seq_len = tf.shape(x_in)[1]
        feature_dim = tf.shape(x_in)[2]
        num_windows = seq_len // win_size
        return tf.reshape(x_in, (batch_size, num_windows, win_size, feature_dim))

    x_reshaped = layers.Lambda(dynamic_reshape)(x)
    attn_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, dropout=0.3)(x_reshaped, x_reshaped)

    def reshape_back(x_in):
        batch_size = tf.shape(x_in)[0]
        seq_len = tf.shape(x_in)[1] * tf.shape(x_in)[2]
        feature_dim = tf.shape(x_in)[3]
        return tf.reshape(x_in, (batch_size, seq_len, feature_dim))

    attn_output = layers.Lambda(reshape_back)(attn_output)
    x = layers.Add()([x, attn_output])
    x = layers.LayerNormalization(epsilon=1e-6)(x)
    return x


# ==================================================== #
# MODEL ARCHITECTURE: MULTISCALE CNN + TRANSFORMER ENCODER #
# ==================================================== #

def build_model(input_shape, num_classes):
    inputs = layers.Input(shape=input_shape)
    x1 = layers.Conv1D(128, 3, activation='relu', padding='same')(inputs)
    x2 = layers.Conv1D(128, 5, activation='relu', padding='same')(inputs)
    x3 = layers.Conv1D(128, 7, activation='relu', padding='same')(inputs)
    x = layers.Concatenate()([x1, x2, x3])

    x = layers.BatchNormalization()(x)
    x = windowed_transformer_encoder(x, window_size=16)
    x = layers.GlobalAveragePooling1D()(x)
    x = layers.Dense(128, activation='relu')(x)
    x = layers.Dropout(0.4)(x)
    outputs = layers.Dense(num_classes, activation='softmax')(x)

    model = models.Model(inputs=inputs, outputs=outputs)
    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model


# ======================================= #
# LOAD AND ENCODE PROTEIN SEQUENCE DATA  #
# ======================================= #

def load_and_process_data(file_path):
    df = pd.read_csv(file_path)

    aa_3to1 = {
        'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D', 'CYS': 'C',
        'GLN': 'Q', 'GLU': 'E', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I',
        'LEU': 'L', 'LYS': 'K', 'MET': 'M', 'PHE': 'F', 'PRO': 'P',
        'SER': 'S', 'THR': 'T', 'TRP': 'W', 'TYR': 'Y', 'VAL': 'V'
    }
    aa_dict = {aa: i for i, aa in enumerate("ACDEFGHIKLMNPQRSTVWY")}

    df = df.dropna()
    y_labels = df.iloc[:, 0].values
    sequences = df.iloc[:, 1:].values
    X_encoded = []

    for row in sequences:
        row_1letter = [aa_3to1.get(str(aa).upper(), 'X') for aa in row]
        encoded = [aa_dict.get(aa, 20) for aa in row_1letter]
        X_encoded.append(encoded)

    X = np.array(X_encoded)
    X_onehot = np.eye(21)[X]

    label_encoder = LabelEncoder()
    y = label_encoder.fit_transform(y_labels)
    y_cat = to_categorical(y)

    return X_onehot, y_cat, y, label_encoder.classes_


# ===================================== #
# HELPER TO FORMAT RESULTS FOR EXPORT  #
# ===================================== #

def format_result(mean, std):
    return f"{round(mean, 3)} ± {round(std, 3)}"


# =================================== #
# MAIN TRAINING & EVALUATION PIPELINE #
# =================================== #

def train_and_evaluate(file_path):
    X_onehot, y_cat, y_raw, class_names = load_and_process_data(file_path)

    metrics = {cls: {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'mcc': []} for cls in range(y_cat.shape[1])}
    q3_scores, overall_precisions, overall_recalls, overall_f1s, overall_mccs = [], [], [], [], []

    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    for train_idx, test_idx in kf.split(X_onehot, y_raw):
        X_train, X_test = X_onehot[train_idx], X_onehot[test_idx]
        y_train, y_test = y_cat[train_idx], y_cat[test_idx]

        model = build_model((X_train.shape[1], X_train.shape[2]), y_cat.shape[1])
        early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

        model.fit(X_train, y_train, validation_split=0.1, epochs=30, batch_size=32, callbacks=[early_stop], verbose=0)

        y_pred = np.argmax(model.predict(X_test), axis=1)
        y_test_classes = np.argmax(y_test, axis=1)

        q3_scores.append(accuracy_score(y_test_classes, y_pred))
        overall_precisions.append(precision_score(y_test_classes, y_pred, average='macro'))
        overall_recalls.append(recall_score(y_test_classes, y_pred, average='macro'))
        overall_f1s.append(f1_score(y_test_classes, y_pred, average='macro'))
        overall_mccs.append(matthews_corrcoef(y_test_classes, y_pred))

        for i in range(y_cat.shape[1]):
            class_mask = (y_test_classes == i)
            if np.sum(class_mask) > 0:
                metrics[i]['accuracy'].append(accuracy_score(class_mask, (y_pred == i)))
                metrics[i]['precision'].append(precision_score((y_test_classes == i), (y_pred == i), zero_division=0))
                metrics[i]['recall'].append(recall_score((y_test_classes == i), (y_pred == i), zero_division=0))
                metrics[i]['f1'].append(f1_score((y_test_classes == i), (y_pred == i), zero_division=0))
                binary_true = (y_test_classes == i).astype(int)
                binary_pred = (y_pred == i).astype(int)
                metrics[i]['mcc'].append(matthews_corrcoef(binary_true, binary_pred))

    results = {'Metric': ['Mean ± Std']}
    results['Q3_Accuracy'] = [format_result(np.mean(q3_scores), np.std(q3_scores, ddof=1))]
    results['Overall_Precision'] = [format_result(np.mean(overall_precisions), np.std(overall_precisions, ddof=1))]
    results['Overall_Recall'] = [format_result(np.mean(overall_recalls), np.std(overall_recalls, ddof=1))]
    results['Overall_F1'] = [format_result(np.mean(overall_f1s), np.std(overall_f1s, ddof=1))]
    results['Overall_MCC'] = [format_result(np.mean(overall_mccs), np.std(overall_mccs, ddof=1))]

    for i, cls_name in enumerate(class_names):
        results[f'{cls_name}_Accuracy'] = [format_result(np.mean(metrics[i]['accuracy']), np.std(metrics[i]['accuracy'], ddof=1))]
        results[f'{cls_name}_Precision'] = [format_result(np.mean(metrics[i]['precision']), np.std(metrics[i]['precision'], ddof=1))]
        results[f'{cls_name}_Recall'] = [format_result(np.mean(metrics[i]['recall']), np.std(metrics[i]['recall'], ddof=1))]
        results[f'{cls_name}_F1'] = [format_result(np.mean(metrics[i]['f1']), np.std(metrics[i]['f1'], ddof=1))]
        results[f'{cls_name}_MCC'] = [format_result(np.mean(metrics[i]['mcc']), np.std(metrics[i]['mcc'], ddof=1))]

    results_df = pd.DataFrame(results)
    results_df.to_excel('myco_ourmodel.xlsx', index=False)


# ============================================ #
# INDEPENDENT TEST SET EVALUATION FUNCTION    #
# ============================================ #

def evaluate_on_independent_test(model, test_file_path):
    X_test, y_cat_test, y_raw_test, _ = load_and_process_data(test_file_path)
    y_pred = np.argmax(model.predict(X_test), axis=1)
    y_test = np.argmax(y_cat_test, axis=1)

    q3 = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='macro', zero_division=0)
    recall = recall_score(y_test, y_pred, average='macro', zero_division=0)
    f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)
    mcc = matthews_corrcoef(y_test, y_pred)

    print("===== Independent Test Set Results =====")
    print(f"Q3 Accuracy: {q3:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"MCC: {mcc:.4f}")

    return {
        "Q3 Accuracy": q3,
        "Precision": precision,
        "Recall": recall,
        "F1 Score": f1,
        "MCC": mcc
    }


# =================== #
# MAIN EXECUTION ENTRY #
# =================== #

if __name__ == "__main__":
    train_and_evaluate("myco_data.csv")

    X_train, y_cat_train, y_raw_train, _ = load_and_process_data("Train_filename.csv")
    final_model = build_model((X_train.shape[1], X_train.shape[2]), y_cat_train.shape[1])
    final_model.fit(X_train, y_cat_train, epochs=20, batch_size=32, verbose=0)

    evaluate_on_independent_test(final_model, "indedependent_dataset.csv")